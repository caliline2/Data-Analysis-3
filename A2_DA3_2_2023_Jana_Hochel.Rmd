---
title: "DA3_Jana_Hochel_Assignment_2"
author: "Jana Hochel"
date: "2023-02-04"
output:
  pdf_document:
    latex_engine: xelatex
---

```{r echo=FALSE, include=FALSE}
#xfun::session_info('tinytex')
#tinytex::tlmgr_install("SimHei")
#tinytex::tlmgr_install("CJK")
#tinytex::tlmgr_install("CJKutf8")
#install.packages('tinytex')
# CLEAR MEMORY
rm(list=ls())


library(tidyverse)
library(knitr)

#Modelling package
library(caret)
# Helper packages
library(dplyr)       # for data wrangling
library(ggplot2)     # for awesome plotting
library(doParallel)  # for parallel backend to foreach
library(foreach)     # for parallel processing with for loops

library(rpart)       # for fitting decision trees
library(ipred)       # for fitting bagged decision trees
# Random forest package
library(ranger)
library(modelsummary)
# install.packages("pdp")
library(pdp)
# Gradient boosting machine
library(gbm)
# Pretty plots
library(rattle)
library(tables)
library(jtools)

#reading Chinese characters
library(tinytex)
library(fixest)


#########################################################################################

# DATA IMPORT, EDA & FEATURES




# Used area
area <- "shanghai"


data <- read_csv("C:\\Users\\Magdalenka Kolacik\\Jankyna zaloha\\CEU\\Data Analytics\\AirBnB\\listings.csv") %>%
  mutate_if(is.character, factor) %>%
  filter(!is.na(price))

spec(data)
ls(data)
data<-data[!is.na(data$price),]

# zero step
# not necessary
#data<-read.csv(paste0(data_in,"listings.csv"))
drops <- c("host_thumbnail_url","host_picture_url","listing_url","thumbnail_url","medium_url","picture_url","xl_picture_url","host_url","last_scraped","description", "experiences_offered", "neighborhood_overview", "notes", "transit", "access", "interaction", "house_rules", "host_about", "host_response_time", "name", "summary", "space", "host_location")
data<-data[ , !(names(data) %in% drops)]

#drop broken lines - where id is not a character of numbers
data$junk<-grepl("[[:alpha:]]", data$id)
data<-subset(data,data$junk==FALSE)
data<-data[1:ncol(data)-1]


#display the class and type of each columns
sapply(data, class)
sapply(data, typeof)

#####################
#formatting columns

#remove percentage signs
for (perc in c("host_response_rate","host_acceptance_rate")){
  data[[perc]]<-gsub("%","",as.character(data[[perc]]))
}

#remove dollar signs from price variables
for (pricevars in c("price")){
  data[[pricevars]]<-gsub("\\$","",as.character(data[[pricevars]]))
  data[[pricevars]]<-as.numeric(as.character(data[[pricevars]]))
}



#format binary variables
#for (binary in c("host_is_superhost","host_has_profile_pic","host_identity_verified","is_locatioexact","requires_license","instant_bookable","require_guest_profile_picture","require_guest_phone_verification")){
#  data[[binary]][data[[binary]]=="f"] <- 0
#  data[[binary]][data[[binary]]=="t"] <- 1
#}


data$amenities<-gsub("\\{","",data$amenities)
data$amenities<-gsub("\\}","",data$amenities)
data$amenities<-gsub('\\"',"",data$amenities)
data$amenities<-as.list(strsplit(data$amenities, ","))


#define levels and dummies 
levs <- levels(factor(unlist(data$amenities)))
data<-cbind(data,as.data.frame(do.call(rbind, lapply(lapply(data$amenities, factor, levs), table))))

drops <- c("translation missing: en.hosting_amenity_49",
           "translation missing: en.hosting_amenity_50")
data<-data[ , !(names(data) %in% drops)]


#data$` TV` <- as.numeric(data$` TV`) 
#data$`[TV` <- as.numeric(data$`[TV`) 
#data$` Window AC unit` <- as.numeric(data$` Window AC unit`) 
#data$` Air conditioning` <- as.numeric(data$` Air conditioning`) 
#data$` Air conditioning]` <- as.numeric(data$` Air conditioning]`)
#data$` Central air conditioning` <- as.numeric(data$` Central air conditioning`)
#$` Portable air conditioning` <- as.numeric(data$` Portable air conditioning`)
#data$`[Air conditioning` <- as.numeric(data$`[Air conditioning`)
#data$` Pool` <- as.numeric(data$` Pool`)
#data$` Private pool`<- as.numeric(data$` Private pool` )
#data$` Shared pool`<- as.numeric(data$` Shared pool`)
#data$` Shared outdoor pool`<- as.numeric(data$` Shared outdoor pool`)

#Price per person
#data<- data %>% mutate(price=price/accommodates) 
data<- data %>% mutate(aircon=(data$` Window AC unit`)+ (data$` Air conditioning`)+(data$` Air conditioning]`)+(data$` Central air conditioning`)+(data$` Portable air conditioning`)+(data$`[Air conditioning`)) 
data<- data %>% mutate(television=(data$` TV`)+ (data$`[TV`)+(data$` TV]`)+(data$` HDTV`)+(data$` TV with `)+(data$` TV with standard cable`))
data<- data %>% mutate(pool=(data$` Private pool`)+ (data$` Pool`)+(data$` Shared outdoor pool`)+(data$` Shared pool`))
data$price
data$television
data$aircon
data$pool

# MINOR STUFF
# data changed marginally, to make it compatible with textbook, we'll drop 27 rows. 
#not_ibook <- read.csv(paste0(data_in,"reviews.csv"), header=TRUE, row.names = 1)
#data<-data %>%
# left_join(not_ibook, by="id")%>%
#  filter(is.na(not_ibook))%>%
# dplyr::select(-not_ibook)

#write csv
#write.csv(data,file=paste0(data_out,"airbnb_londocleaned.csv"))

#############################

###########################
# We focus on normal apartments, n<7
data <- data %>% filter(accommodates < 7)



# copy a variable - purpose later, see at variable importance
data <- data %>% mutate(accommodates_copy = accommodates)

#```

#```{r echo=FALSE, include=TRUE}
# basic descr stat -------------------------------------------
skimr::skim(data)

data = subset(data, data$price>0 )


data %>% 
  summarise(
    frequency=n(),
    min = min(price),
    P1 = quantile(price, 0.01), 
    D1 = quantile(price, 0.1), 
    Q1 = quantile(price, 0.25), 
    Me = quantile(price, 0.5), 
    Q3 = quantile(price, 0.75), 
    D9 = quantile(price, 0.9), 
    P99 = quantile(price, 0.99),
    max = max(price))  

Hmisc::describe(data$price)

datasummary( room_type * property_type  ~ Percent() , data = data )
datasummary( room_type + property_type  ~ Percent() , data = data )


# create train and holdout samples 
# train is where we do it all, incl CV


set.seed(20230201)

#as.integer(createDataPartition(data$price, p = 0.7, list = FALSE, na.rm=TRUE))

train_indices <- as.integer(createDataPartition(data$price, p = 0.7, list = FALSE))
data_train <- data[train_indices, ]

data_holdout <- data[-train_indices, ]


#train_indices<-createFolds(data$price, k = 10, list = TRUE, returnTrain = FALSE)


# Check the number of observations
dim(data_train)
dim(data_holdout)


# Random forest mixes poor trees = weak learners and combines them in a way to be more efficient.
#########################################################################################

# DEFINE MODELS: FROM SIMPLE TO EXTENDED


ls(data)
# Basic Variables incl. neighborhood
basic_vars <- c(
  "accommodates", "beds",
  "property_type","room_type")


# reviews
reviews <- c("number_of_reviews","review_scores_location","review_scores_communication","review_scores_cleanliness","review_scores_checkin","review_scores_accuracy")

data$number_of_reviews

data$review_scores_accuracy

amenities <- c("television", 'pool',"aircon")

# dummy variables
amenities <-  grep("^d_.*", names(data), value = TRUE)

# interactions for the LASSO
# as seen in Chapter 14 EDA


X1  <- c("accommodates*property_type",  "room_type*property_type",  "room_type*television",
         "aircon*property_type", "pool*property_type")
# with boroughs
X2  <- c("property_type*neighbourhood_cleansed", "room_type*neighbourhood_cleansed",
         "accommodates*neighbourhood_cleansed" )


predictors_1 <- c(basic_vars)
predictors_2 <- c(basic_vars, reviews)
predictors_3 <- c(basic_vars, reviews, amenities, X1, X2)

####################################################################### Bagging Regressor

set.seed(1234)

# train bagged model
#bagmodel_1 <- bagging(
#  formula(paste0("price ~", paste0(predictors_1, collapse = " + "))),
#  data = data,
#  nbagg = 50,  
#  coob = TRUE,
#  control = rpart.control(minsplit = 2, cp = 0)
#)

#bagmodel_1


set.seed(1234)

# train bagged model
bagmodel_2 <- bagging(
  formula(paste0("price ~", paste0(predictors_2, collapse = " + "))),
  data = data,
  nbagg = 50,  
  coob = TRUE,
  control = rpart.control(minsplit = 2, cp = 0)
)

bagmodel_2

#set.seed(1234)

# train bagged model
#bagmodel_3 <- bagging(
#  formula(paste0("price ~", paste0(predictors_3, collapse = " + "))),
#  data = data,
#  nbagg = 50,  
#  coob = TRUE,
#  control = rpart.control(minsplit = 2, cp = 0)
#)

#bagmodel_3


# evaluate results

#bagresults <- resamples(
#  list(
#    bagmodel_1  = bagmodel_1,
#    bagmodel_2  = bagmodel_2
#    bagmodel_3  = bagmodel_3
#  )
#)

#bagresults



######################################################################
# RANDOM FORESTS 

# do 5-fold CV

traicontrol <- trainControl(method = "cv",
                              number = 5,
                              verboseIter = FALSE)

# simpler model - random forest

# set tuning

tune_grid <- expand.grid(
  .mtry = c(8),
  #number of variables in a tree
  .splitrule = "variance",
  .min.node.size = c(50)
)
#)
# note
#   mtry: number of variables to possibly split at in each node
#   splitrule: the default splitting rule during random forests tree building consists
#           of selecting, out of all splits of the (randomly selected) candidate variables, 
#           the split that minimizes the Gini impurity (in the case of classification) 
#           and the SSE (in case of regression); 
#           other options for regressions: "extratrees", "maxstat" or "beta" with default "variance"
#   see more here: https://bradleyboehmke.github.io/HOML


# run model

set.seed(1234)
system.time({
rmodel_1 <- train(
  formula(paste0("price ~", paste0(predictors_1, collapse = " + "))),
  data = data_train,
  method = "ranger",
  trControl = traicontrol,
  tuneGrid = tune_grid,
  importance = "impurity",
  na.action=na.exclude
)
})
#```

#```{r echo=FALSE, include=TRUE}
rmodel_1
#```

#```{r echo=FALSE, include=FALSE}
# more complicated model with the same tuning parameters

set.seed(1234)
system.time({
  rmodel_2 <- train(
    formula(paste0("price ~", paste0(predictors_2, collapse = " + "))),
    data = data_train,
    method = "ranger",
    trControl = traicontrol,
    tuneGrid = tune_grid,
    importance = "impurity",
    na.action=na.exclude
  )
})
#```

#```{r echo=FALSE, include=TRUE}
rmodel_2
#```

#```{r echo=FALSE, include=FALSE}

set.seed(1234)
system.time({
  rmodel_3 <- train(
    formula(paste0("price ~", paste0(predictors_3, collapse = " + "))),
    data = data_train,
    method = "ranger",
    trControl = traicontrol,
    tuneGrid = tune_grid,
    importance = "impurity",
    na.action=na.exclude
  )
})
#```

#```{r echo=FALSE, include=TRUE}
rmodel_3

#```

#```{r echo=FALSE, include=FALSE}
# evaluate results

results <- resamples(
  list(
    model_1  = rmodel_1,
    model_2  = rmodel_2,
    model_3  = rmodel_3
  )
)

results

# note: the 'resamples' function provides methods for collection, analyzing and 
#   visualizing a set of resampling results from a common data set
#```

#```{r echo=FALSE, include=TRUE}
summary(results)
#```




#```{r echo=FALSE, include=FALSE}
# model 2 with an expanded grid - will take forever to run
tune_grid <- expand.grid(
   .mtry = c(8, 10, 12),
   .splitrule = "variance",
   .min.node.size = c(5, 10, 15)
)
# 
# set.seed(1234)
# system.time({
# rmodel_2 <- train(
#   formula(paste0("price ~", paste0(predictors_2, collapse = " + "))),
#   data = data_train,
#   method = "ranger",
#   trControl = traicontrol,
#   tuneGrid = tune_grid,
#   importance = "impurity"
# )
# })
# 
# rmodel_2

# auto tuning - takes even longer
# set.seed(1234)
# system.time({
#   rmodel_2auto <- train(
#     formula(paste0("price ~", paste0(predictors_2, collapse = " + "))),
#     data = data_train,
#     method = "ranger",
#     trControl = traicontrol,
#     importance = "impurity"
#   )
# })
# rmodel_2auto 



#########################################################################################
#
# DIAGNOSTICS 

# Variable Importance Plots 

# first need a function to calculate grouped varimp
group.importance <- function(rf.obj, groups) {
  var.imp <- as.matrix(sapply(groups, function(g) {
    sum(importance(rf.obj)[g], na.rm = TRUE)
  }))
  colnames(var.imp) <- "MeanDecreaseGini"
  return(var.imp)
}


# variable importance plot
# 1) full varimp plot, full
# 2) varimp plot grouped
# 3) varimp plot , top 10
# 4) varimp plot  w copy, top 10

rmodel_2_var_imp <- ranger::importance(rmodel_2$finalModel)/1000
rmodel_2_var_imp_data <-
  data.frame(varname = names(rmodel_2_var_imp),imp = rmodel_2_var_imp) %>%
  mutate(varname = gsub("neighbourhood_cleansed", "Borough:", varname) ) %>%
  mutate(varname = gsub("room_type", "Room type:", varname) ) %>%
  arrange(desc(imp)) %>%
  mutate(imp_percentage = imp/sum(imp))
#```

#```{r echo=FALSE, include=TRUE}
rmodel_2_var_imp_data


# quick look

plot(varImp(rmodel_2))


# only above a cutoff

cutoff = 300

ggplot(
    rmodel_2_var_imp_data[rmodel_2_var_imp_data$imp>cutoff,],
    aes(x=reorder(varname, imp), y=imp_percentage)) +
  geom_point(color='black', size=1.5) +
  geom_segment(
    aes(x=varname,xend=varname,y=0,yend=imp_percentage), 
    color='black', size=1) +
  ylab("Importance (Percent)") +
  xlab("Variable Name") +
  coord_flip() +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  theme_bw() +
  theme(axis.text.x = element_text(size=8), axis.text.y = element_text(size=8),
        axis.title.x = element_text(size=8), axis.title.y = element_text(size=8))



# full varimp plot, top 10 only

varianceimp<-ggplot(
    rmodel_2_var_imp_data[1:10,], 
    aes(x=reorder(varname, imp), y=imp_percentage)) +
  geom_point(color='black', size=3) +
  geom_segment(
    aes(x=varname,xend=varname,y=0,yend=imp_percentage), 
    color='black', size=1) +
  ylab("Importance (Percent)") +
  xlab("Variable Name") +
  labs(title = 'Variable importance plots') + 
  coord_flip() +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  theme_bw()




# grouped varimp plot:
#   keep binaries created off factors together
#```


#```{r echo=FALSE, include=TRUE}
# Udata
group.importance <- function(rf.obj, groups) {
  var.imp <- as.matrix(sapply(groups, function(g) {
    sum(ranger::importance(rf.obj)[g], na.rm = TRUE)
  }))
  colnames(var.imp) <- "MeanDecreaseGini"
  return(var.imp)
}

varnames <- rmodel_2$finalModel$xNames
neighbourhood_cleansed_varnames <- grep("neighbourhood_cleansed",varnames, value = TRUE)
cancellatiopolicy_varnames <- grep("cancellatiopolicy",varnames, value = TRUE)
bed_type_varnames <- grep("bed_type",varnames, value = TRUE)
property_type_varnames <- grep("property_type",varnames, value = TRUE)
room_type_varnames <- grep("room_type",varnames, value = TRUE)

groups <- list(neighbourhood_cleansed=neighbourhood_cleansed_varnames,
               cancellatiopolicy = cancellatiopolicy_varnames,
               bed_type = bed_type_varnames,
               property_type = property_type_varnames,
               room_type = room_type_varnames,
               bathroom = "bathroom",
               days_since = "days_since",
               accommodates = "accommodates",
               beds = "beds")

rmodel_2_var_imp_grouped <- group.importance(rmodel_2$finalModel, groups)
rmodel_2_var_imp_grouped_data <- data.frame(
  varname = rownames(rmodel_2_var_imp_grouped),
  imp = rmodel_2_var_imp_grouped[,1])  %>%
  mutate(imp_percentage = imp/sum(imp))

#```

#```{r echo=FALSE, include=TRUE}
ggplot(
    rmodel_2_var_imp_grouped_data, 
    aes(x=reorder(varname, imp), y=imp_percentage)) +
  geom_point(color='black', size=3) +
  geom_segment(
    aes(x=varname,xend=varname,y=0,yend=imp_percentage), 
    color='black', size=1) +
  ylab("Importance (Percent)") +   
  xlab("Variable Name") +
  labs(title = 'Grouped variable importance plots') + 
  coord_flip() +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  theme_bw()

#Looking at the high level groups, the property and room type also plays a huge role.

# PDP: partial dependence plots 
#```

#```{r echo=FALSE, include=FALSE}
# 1) Number of accommodates
pdp_acc <- pdp::partial(rmodel_2, 
                          pred.var = "accommodates", 
                          pred.grid = distinct_(data_holdout, "accommodates"), 
                          train = data_train)

#```

#```{r echo=FALSE, include=TRUE}
predictionapprice<-pdp_acc %>%
  autoplot( ) +
  geom_point(color='black', size=2) +
  geom_line(color='black', size=1) +
  ylab("Predicted price") +
  xlab("Accommodates (persons)") +
  labs(title = 'Predicted price per apartment') + 
  scale_x_continuous(limit=c(1,7), breaks=seq(1,7,1))+
  theme_bw()


# OLS 

model1 <- as.formula(price ~ accommodates + beds+number_of_reviews+review_scores_location+review_scores_communication+review_scores_cleanliness+review_scores_checkin+review_scores_accuracy+pool+television+aircon)
pred1 <- feols(model1, data=data, vcov = 'hetero')
summary(pred1)

# COMPETING MODELS


#data <- data %>% dplyr::select(EarningPH,IT_Occupation,age,marital,sex,ownchild,highereducation)

# Add new observation
new <- tibble(accommodates=2, beds=2, number_of_reviews=10, review_scores_location=5,review_scores_communication=5,review_scores_cleanliness=5,review_scores_checkin=5,review_scores_accuracy=5)

new2 <- tibble(accommodates=3, beds=3, number_of_reviews=10, review_scores_location=5,review_scores_communication=5,review_scores_cleanliness=5,review_scores_checkin=5,review_scores_accuracy=5)

new3 <- tibble(accommodates=4, beds=4, number_of_reviews=10, review_scores_location=5,review_scores_communication=5,review_scores_cleanliness=5,review_scores_checkin=5,review_scores_accuracy=5)

new4 <- tibble(accommodates=5, beds=5, number_of_reviews=10, review_scores_location=5,review_scores_communication=5,review_scores_cleanliness=5,review_scores_checkin=5,review_scores_accuracy=5)

new5 <- tibble(accommodates=6, beds=6, number_of_reviews=10, review_scores_location=5,review_scores_communication=5,review_scores_cleanliness=5,review_scores_checkin=5,review_scores_accuracy=5)

# cylinders
#data <- data %>%
#  mutate(married = ifelse(marital<3,1,0))

# OLS 

model8 <- as.formula(price~ accommodates + beds+number_of_reviews+review_scores_location+review_scores_communication+review_scores_cleanliness+review_scores_checkin+review_scores_accuracy)

class(model8)


# Predict price with only 2 predictors (Model1)
pred1 <- feols(model8, data=data, vcov = 'hetero')
summary(pred1)

#View RMSE
pred1

# Standard errors of residuals
p1 <- predict(pred1, data)
resid_p1 <- p1-data$price
summary(resid_p1)


# predict value for newly added obs
pred1_new <- predict(pred1, newdata = new ,se.fit = TRUE, interval = "prediction")
p1<- pred1_new$fit
p1

# predict value for newly added obs
pred2_new <- predict(pred1, newdata = new2 ,se.fit = TRUE, interval = "prediction")
p2<- pred2_new$fit
p2

# predict value for newly added obs
pred3_new <- predict(pred1, newdata = new3 ,se.fit = TRUE, interval = "prediction")
p3<- pred3_new$fit
p3


# predict value for newly added obs
pred4_new <- predict(pred1, newdata = new4 ,se.fit = TRUE, interval = "prediction")
p4<- pred4_new$fit
p4

# predict value for newly added obs
pred5_new <- predict(pred1, newdata = new5 ,se.fit = TRUE, interval = "prediction")
p5<- pred5_new$fit
p5


#get model rmse
data$p1_rmse <- predict(pred1, data)
data$p1_rmse

log_na <- is.na( data$p1 )
log_na

rmse1 <- RMSE(data$p1[!log_na],data$price[!log_na])

rmse1




```

# Apartment Rentals 

## Price Prediction Winter 2022

The goal is to help a Sheraton hotel to diversify its revenue stream by redeveloping part of its Shanghai hotels to rental apartments. The benefits are longer contracts and stickiness of customers as apartments may be rented for a longer period of time. This can assure stable cashflow in these turbulent times. The apartments will be small and mid-size hosting 2-6 guests. 

The company is set to price their new apartments to be able to create a business plan for investors. 

The design is yet to be determined. Thus, we will use all types of accommodation to analyse the preferable positining on the market.

This report summarises the predicted price per apartment per night in Shaghai Sheraton Apartment Co.

## Data
The data was kindly provided by Inside Airbnb. The dataset used is from the first quarter of 2022 as the hotel is expected to open apartments in the first quarter of 2024.
For more information please refer to: http://insideairbnb.com/get-the-data/

## Feature Engineering

The model analyses key properties includigng type of room and property, amenities, and the AirBnB user reviews such as location rating. As the Sheraton Fengxian is right in the center and has been rated 5* in all categories at well-know sites such as booking.com, we will use this a baseline for our prediction. 

## Label Engineering
The model has been tested for both cost per person per night and price of apartment per night.

## Sample design
Apartments larger than for 6 guests were dropped. Accommodation for one person was left in the sample as even larger apartments may host fewer people.

## Considerations

### Heterogenous price

When tackling this assignment, we have selected price per apartment. All the models were tested with price per guest.

This technique has some flaws as larger apartments may host fewer guests. Moreover, AirBnB recalculates the price based on the number of actual guests. Thus, the price is not fully representative but it is a good approximation.

### Heterogenous amenities

The tags that hotels used to describe their amenities vary and thus, it is challenging to compare like-for-like. For the purpose of this model, three amenities were selected as the hotel may have to face a higher capital expenditure to fit the apartment with these items - air conditing, television, and a pool. 

### Reviews

The reviews do not reflect the actual performance of the abode but rather the perception of the users. This may be skewed should the user have had different expectation such as in case of expensive hotels or cheap motels.

## The Model

Three types of models were used to analyse the data. First, OLS - simple linear regression. Second, Random Forest. Third, Bagging Regressor. The black box bootstrapping models helped greatly to improve predictive power.

# Testing different models

## Bagging Regressor
```{r echo=FALSE, include=TRUE, comment=NA,message=FALSE,warning = FALSE}


bagmodel_2
```

## Random Forest

```{r echo=FALSE, include=TRUE, comment=NA,message=FALSE,warning = FALSE}



#print(knitr::kable(summary(results)))
summary(results)


```

We may see that despite the model 3 has higher R square, it is unecessarily complex whilst achieving only a marginal improvement of predictive power.anova.test.Nonetheless, the error term and also B are higher. Thus, the best model seems to be number 2 marrying the simplicity and explanatory power.

## OLS

```{r echo=FALSE, include=TRUE, comment=NA,message=FALSE,warning = FALSE}
summary(pred1)


```
OLS displays very low RMSE compared to other models but the R-squared is lower.

## Verdict
The lowest RMSE display OLS and Random Forest model 2.
Thus, these two models were used to predict the price, combining and comparing simplicity and predictive power.

## Analysis of variables

The highest importance display the variables such as number of guests that may be accommodated in the property and the number of beds.
Nonetheless, we may safely assume the two are correlated. Second, the reviews have a large impact on the price such as location and the number of review. Second, it is important whether the room is private or shared, and privacy in general as there is premium if you rent an entire unit. Altough, this is not going to be a technical issue in Sheraton Shanghai Fengxian, the marketing departments may emphasize it when promoting the apartments - highlighting the unique intimate VIP uninturupted experience whilst staying in this busy city.

```{r echo=FALSE, include=TRUE, comment=NA,message=FALSE,warning = FALSE}

varianceimp
```

The random forest-driven prediction shows there is a dimishing increase in price for every additional guest. There is a significant difference between a single visitor and a couple.There is a similar shift beyond 3 people of larger families and party groups visiting. Beyond 4 guests the price per person decreases only marginally. Thus, larger groups do pay more but they pay less per person.

The same pattern is captured by the OLS.

```{r echo=FALSE, include=TRUE, comment=NA,message=FALSE,warning = FALSE}
predictionapprice

priceperroomOLS= data.frame(accommodates=c('2','3','4','5','6'), price=c(p1,p2,p3,p4,p5))
kable(priceperroomOLS, caption='OLS Predicted price per apartment')
#p1
#p2
#p3
#p4
#p5



```


According to OLS, the price per apartment for two starts at 313 dollars for two people. For a fully occupied apartment/property for 6 it is 527 dollars. Random Forest Model is a better fit and suggests a smaller difference, 345 dollars for two and 428 dollars for 6 people.

## Next steps.

Sheraton is advised analyse a variable cost per guest (bed/energy/toiletries) and fixed cost such as a bathroom to determine the best design in terms of the highest ROI. Should the fixed cost be low, it may be desirable to build smaller apartments for 2 and 3 individuals. Similarly, the visitors in China may prefer smaller apartments as sharing has become less popular due to COVID-19 lockdowns. Thus, this analysis should be repeated after COVID-19 is gone.

### Acknowledgement
This report benefited of work and generous contribution of Gabor Bekes and Peter Duronelly.
